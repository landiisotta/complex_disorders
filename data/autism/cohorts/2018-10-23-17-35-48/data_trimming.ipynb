{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_folder = 'autism'\n",
    "date_time_folder = '2018-10-23-17-35-48'\n",
    "data_folder =  os.path.expanduser('~/data1/complex_disorders/data/%s/cohorts/%s/' %(disease_folder, date_time_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_tags = [2568, 7628, 7301, 2088, 6118, 5361, 7321, 8684, 11299]\n",
    "ad_tags = [654, 11559]\n",
    "mm_tags = [4019, 372, 2970, 3077, 8316]\n",
    "tags = [asd_tags, mm_tags, ad_tags]\n",
    "\n",
    "TRIM_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'padded_ehrs.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    padded_ehrs = []\n",
    "    for r in rd:\n",
    "        padded_ehrs += [list(map(int, r))]\n",
    "        \n",
    "with open(os.path.join(data_folder, 'mrn_classes.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrn_classes = {}\n",
    "    next(rd)\n",
    "    for r in rd:\n",
    "        mrn_classes[r[0]] = r[1::]\n",
    "        \n",
    "with open(os.path.join(data_folder, 'ordered_mrns.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    list_classes = []\n",
    "    ordered_mrns = []\n",
    "    for r in rd:\n",
    "        ordered_mrns.append(r[0])\n",
    "        list_classes.append(mrn_classes[str(r[0])][0])        \n",
    "        \n",
    "with open('cohort-vocab.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    vocab = {}\n",
    "    next(rd)\n",
    "    for r in rd:\n",
    "        vocab[r[1]] = r[0]\n",
    "\n",
    "with open('mt_to_ix.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    old_vocab = {}\n",
    "    #next(rd)\n",
    "    for r in rd:\n",
    "        old_vocab[r[1]] = int(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ehrs = []\n",
    "new_ordered_mrn = []\n",
    "new_list_classes = []\n",
    "for idx, e in enumerate(padded_ehrs):\n",
    "    e_tmp = list(filter(lambda x: x>0, e))\n",
    "    if len(e_tmp) > TRIM_LEN:\n",
    "        c = list_classes[idx][0]\n",
    "        #print(c)\n",
    "        #print(tags[int(c)-1])\n",
    "        #print(e)\n",
    "        if int(c) > 0:\n",
    "            tmp = []\n",
    "            for t in tags[int(c)-1]:\n",
    "                if t in e_tmp:\n",
    "                    tmp.append(e_tmp.index(t))\n",
    "            first_diag_idx = min(tmp)\n",
    "            ctrl = e_tmp[first_diag_idx:len(e_tmp)]\n",
    "            if len(ctrl) >= TRIM_LEN:\n",
    "                new_ordered_mrn.append(ordered_mrns[idx])\n",
    "                new_list_classes += list_classes[idx]\n",
    "                trimmed_ehrs.append(e_tmp[first_diag_idx:first_diag_idx+TRIM_LEN])\n",
    "            else:\n",
    "                new_ordered_mrn.append(ordered_mrns[idx])\n",
    "                new_list_classes += list_classes[idx]\n",
    "                trimmed_ehrs.append([e_tmp[first_diag_idx]]+e_tmp[0:TRIM_LEN-1])\n",
    "        else: \n",
    "            new_ordered_mrn.append(ordered_mrns[idx])\n",
    "            new_list_classes += list_classes[idx]\n",
    "            trimmed_ehrs.append(e_tmp[0:TRIM_LEN])\n",
    "\n",
    "    elif len(e_tmp) == TRIM_LEN:\n",
    "        new_ordered_mrn.append(ordered_mrns[idx])\n",
    "        new_list_classes += list_classes[idx]\n",
    "        trimmed_ehrs.append(e_tmp[0:TRIM_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570, 4241, 4342, 429, 2390, 1907, 3305, 4563, 8591], [1968, 0, 1172, 1821], [76]]\n"
     ]
    }
   ],
   "source": [
    "new_vocab = {}\n",
    "count = 0\n",
    "for trim_l in trimmed_ehrs:\n",
    "    for tok in trim_l:\n",
    "        if tok not in new_vocab and tok!=0:\n",
    "            new_vocab[tok] = count\n",
    "            count += 1\n",
    "            \n",
    "new_trimmed_ehrs = []\n",
    "for te in trimmed_ehrs:\n",
    "    tmp = []\n",
    "    for t in te:\n",
    "        tmp.append(new_vocab[t])\n",
    "    new_trimmed_ehrs.append(tmp)\n",
    "\n",
    "tags_trimmed = [[new_vocab[i] for i in asd_tags if i in new_vocab.keys()], \n",
    "                [new_vocab[i] for i in mm_tags if i in new_vocab.keys()],\n",
    "                [new_vocab[i] for i in ad_tags if i in new_vocab.keys()]]\n",
    "\n",
    "print(tags_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3751\n",
      "OTH (no overlapping): 288 -- ASD: 312 -- MM: 1394 -- AD: 1757\n"
     ]
    }
   ],
   "source": [
    "counts = {'0':0, '1':0, '2':0, '3':0}\n",
    "for i in new_list_classes:\n",
    "    counts[str(i)] += 1\n",
    "print(len(trimmed_ehrs))\n",
    "print(\"OTH (no overlapping): {0} -- ASD: {1} -- MM: {2} -- AD: {3}\".format(counts['0'], counts['1'], counts['2'], counts['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'trimmed_ehrs.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_trimmed_ehrs:\n",
    "        wr.writerow(w)\n",
    "\n",
    "with open(os.path.join(data_folder, 'TRIMMEDordered_mrns.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_ordered_mrn:\n",
    "        wr.writerow([w])\n",
    "        \n",
    "with open(os.path.join(data_folder, 'TRIMMEDcohort-vocab.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for old, new in new_vocab.items():\n",
    "        wr.writerow([vocab[str(old_vocab[str(old)])], new])\n",
    "        \n",
    "with open(os.path.join(data_folder, 'TRIMMEDordered_labels.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_list_classes:\n",
    "        wr.writerow(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for m, c in mrn_classes.items():\n",
    "    if c[0]=='1' and m in new_ordered_mrn:\n",
    "        if len(list(filter(lambda x: x > 0, padded_ehrs[ordered_mrns.index(m)]))) >= 100:\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
