{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_folder = 'autism'\n",
    "date_time_folder = '2018-10-28-7-42-17'\n",
    "data_folder =  os.path.expanduser('~/data1/complex_disorders/data/%s/cohorts/%s/' %(disease_folder, date_time_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_tags = [7495, 7957, 2449, 5357, 11868, 12523, 7529, 5372, 9023]\n",
    "adhd_tags = [11532, 2177, 2151]\n",
    "mm_tags = [2892, 4085, 8642, 3091, 372]\n",
    "tags = [asd_tags, mm_tags, adhd_tags]\n",
    "\n",
    "TRIM_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'ordered_ehrs.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    ordered_ehrs = []\n",
    "    for r in rd:\n",
    "        ordered_ehrs += [list(map(int, r))]\n",
    "        \n",
    "with open(os.path.join(data_folder, 'mrn_classes.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrn_classes = {}\n",
    "    next(rd)\n",
    "    for r in rd:\n",
    "        mrn_classes[r[0]] = r[1::]\n",
    "        \n",
    "with open(os.path.join(data_folder, 'ordered_mrns.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    list_classes = []\n",
    "    ordered_mrns = []\n",
    "    for r in rd:\n",
    "        ordered_mrns.append(r[0])\n",
    "        list_classes.append(mrn_classes[str(r[0])][0])        \n",
    "        \n",
    "with open('cohort-vocab.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    vocab = {}\n",
    "    next(rd)\n",
    "    for r in rd:\n",
    "        vocab[r[1]] = r[0]\n",
    "\n",
    "with open('mt_to_ix.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    old_vocab = {}\n",
    "    #next(rd)\n",
    "    for r in rd:\n",
    "        old_vocab[r[1]] = int(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_ehrs = []\n",
    "new_ordered_mrn = []\n",
    "new_list_classes = []\n",
    "for idx, e in enumerate(ordered_ehrs):\n",
    "    e_tmp = list(filter(lambda x: x>=0, e))\n",
    "    if len(e_tmp) > TRIM_LEN:\n",
    "        c = list_classes[idx][0]\n",
    "        #print(c)\n",
    "        #print(tags[int(c)-1])\n",
    "        #print(e)\n",
    "        if int(c) > 0:\n",
    "            tmp = []\n",
    "            for t in tags[int(c)-1]:\n",
    "                if t in e_tmp:\n",
    "                    tmp.append(e_tmp.index(t))\n",
    "            first_diag_idx = min(tmp)\n",
    "            ctrl = e_tmp[first_diag_idx:len(e_tmp)]\n",
    "            if len(ctrl) >= TRIM_LEN:\n",
    "                new_ordered_mrn.append(ordered_mrns[idx])\n",
    "                new_list_classes += list_classes[idx]\n",
    "                trimmed_ehrs.append(e_tmp[first_diag_idx:first_diag_idx+TRIM_LEN])\n",
    "            else:\n",
    "                new_ordered_mrn.append(ordered_mrns[idx])\n",
    "                new_list_classes += list_classes[idx]\n",
    "                trimmed_ehrs.append([e_tmp[first_diag_idx]]+e_tmp[0:TRIM_LEN-1])\n",
    "        else: \n",
    "            new_ordered_mrn.append(ordered_mrns[idx])\n",
    "            new_list_classes += list_classes[idx]\n",
    "            trimmed_ehrs.append(e_tmp[0:TRIM_LEN])\n",
    "\n",
    "    elif len(e_tmp) == TRIM_LEN:\n",
    "        new_ordered_mrn.append(ordered_mrns[idx])\n",
    "        new_list_classes += list_classes[idx]\n",
    "        trimmed_ehrs.append(e_tmp[0:TRIM_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4376, 4309, 506, 1769, 8502, 9801, 3228, 3714, 4628], [1087, 1800, 1712, 0], [7890, 904, 423]]\n"
     ]
    }
   ],
   "source": [
    "new_vocab = {}\n",
    "count = 0\n",
    "for trim_l in trimmed_ehrs:\n",
    "    for tok in trim_l:\n",
    "        if tok not in new_vocab:\n",
    "            new_vocab[tok] = count\n",
    "            count += 1\n",
    "            \n",
    "new_trimmed_ehrs = []\n",
    "for te in trimmed_ehrs:\n",
    "    tmp = []\n",
    "    for t in te:\n",
    "        tmp.append(new_vocab[t])\n",
    "    new_trimmed_ehrs.append(tmp)\n",
    "\n",
    "tags_trimmed = [[new_vocab[i] for i in asd_tags if i in new_vocab.keys()], \n",
    "                [new_vocab[i] for i in mm_tags if i in new_vocab.keys()],\n",
    "                [new_vocab[i] for i in adhd_tags if i in new_vocab.keys()]]\n",
    "\n",
    "print(tags_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4512\n",
      "OTH (no overlapping): 1238 -- ASD: 405 -- MM: 1405 -- ADHD: 1464\n"
     ]
    }
   ],
   "source": [
    "counts = {'0':0, '1':0, '2':0, '3':0}\n",
    "for i in new_list_classes:\n",
    "    counts[str(i)] += 1\n",
    "print(len(trimmed_ehrs))\n",
    "print(\"OTH (no overlapping): {0} -- ASD: {1} -- MM: {2} -- ADHD: {3}\".format(counts['0'], counts['1'], counts['2'], counts['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'trimmed_ehrs.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_trimmed_ehrs:\n",
    "        wr.writerow(w)\n",
    "\n",
    "with open(os.path.join(data_folder, 'TRIMMEDordered_mrns.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_ordered_mrn:\n",
    "        wr.writerow([w])\n",
    "        \n",
    "with open(os.path.join(data_folder, 'TRIMMEDcohort-vocab.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for old, new in new_vocab.items():\n",
    "        wr.writerow([vocab[str(old_vocab[str(old)])], new])\n",
    "        \n",
    "with open(os.path.join(data_folder, 'TRIMMEDordered_labels.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, delimiter=',')\n",
    "    for w in new_list_classes:\n",
    "        wr.writerow(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
